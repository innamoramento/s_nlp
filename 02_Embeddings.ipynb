{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02_Embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/innamoramento/s_nlp/blob/main/02_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfbLLXj-4lLp"
      },
      "source": [
        "# Семинар 2: Векторы слов\n",
        "\n",
        "Другие курсы на ту же тему:\n",
        "* https://github.com/DanAnastasyev/DeepNLP-Course: Курс Дани Анастасьева, Week 2\n",
        "* https://www.youtube.com/watch?v=ERibwqs9p38: Stanford CS224n, Lecture 2\n",
        "* https://github.com/deepmipt/deep-nlp-seminars: Курс DeepMIPT, Seminar 2\n",
        "\n",
        "\n",
        "Контакты: Telegram @YallenGusev, почта ilya.gusev@phystech.edu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsdstjT7ARIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8441b1e1-04ef-40c8-9074-2e9937851bfe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_pQniyAAg8G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d48b0f8c-e368-4675-cd04-92f6e2905923"
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tL_FPZK2jkM",
        "outputId": "6df772f0-f12f-4d35-d6b1-bf8497527b90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get update\n",
        "!apt-get install -y python-setuptools python-pip\n",
        "!pip install --upgrade pybind11 setuptools"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [43.6 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
            "Get:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [66.5 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,881 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [45.6 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,708 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [309 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,307 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,376 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [284 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,140 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [875 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [49.2 kB]\n",
            "Fetched 11.4 MB in 7s (1,701 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip-whl python-pkg-resources python-secretstorage\n",
            "  python-six python-wheel python-xdg\n",
            "Suggested packages:\n",
            "  python-crypto-doc python-cryptography-doc python-cryptography-vectors\n",
            "  python-dbus-dbg python-dbus-doc python-enum34-doc python-gi-cairo\n",
            "  gnome-keyring libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-fs\n",
            "  python-gdata python-keyczar python-secretstorage-doc python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  libpython-all-dev python-all python-all-dev python-asn1crypto\n",
            "  python-cffi-backend python-crypto python-cryptography python-dbus\n",
            "  python-enum34 python-gi python-idna python-ipaddress python-keyring\n",
            "  python-keyrings.alt python-pip python-pip-whl python-pkg-resources\n",
            "  python-secretstorage python-setuptools python-six python-wheel python-xdg\n",
            "0 upgraded, 22 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 3,431 kB of archives.\n",
            "After this operation, 10.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libpython-all-dev amd64 2.7.15~rc1-1 [1,092 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all amd64 2.7.15~rc1-1 [1,076 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-all-dev amd64 2.7.15~rc1-1 [1,100 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-asn1crypto all 0.24.0-1 [72.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-cffi-backend amd64 1.11.5-1 [63.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-crypto amd64 2.6.1-8ubuntu2 [244 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-enum34 all 1.1.6-2 [34.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-idna all 2.6-1 [32.4 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-ipaddress all 1.0.17-1 [18.2 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-six all 1.11.0-2 [11.3 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-cryptography amd64 2.1.4-1ubuntu1.4 [276 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-dbus amd64 1.2.6-1 [90.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 python-gi amd64 3.26.1-2ubuntu1 [197 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-secretstorage all 2.3.1-2 [11.8 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyring all 10.6.0-1 [30.6 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-keyrings.alt all 3.0-1 [16.7 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip-whl all 9.0.1-2.3~ubuntu1.18.04.4 [1,653 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 python-pip all 9.0.1-2.3~ubuntu1.18.04.4 [151 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-pkg-resources all 39.0.1-2 [128 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic/main amd64 python-setuptools all 39.0.1-2 [329 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-wheel all 0.30.0-0.2 [36.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic/universe amd64 python-xdg all 0.25-4ubuntu1 [31.3 kB]\n",
            "Fetched 3,431 kB in 3s (1,184 kB/s)\n",
            "Selecting previously unselected package libpython-all-dev:amd64.\n",
            "(Reading database ... 145483 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libpython-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all.\n",
            "Preparing to unpack .../01-python-all_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-all-dev.\n",
            "Preparing to unpack .../02-python-all-dev_2.7.15~rc1-1_amd64.deb ...\n",
            "Unpacking python-all-dev (2.7.15~rc1-1) ...\n",
            "Selecting previously unselected package python-asn1crypto.\n",
            "Preparing to unpack .../03-python-asn1crypto_0.24.0-1_all.deb ...\n",
            "Unpacking python-asn1crypto (0.24.0-1) ...\n",
            "Selecting previously unselected package python-cffi-backend.\n",
            "Preparing to unpack .../04-python-cffi-backend_1.11.5-1_amd64.deb ...\n",
            "Unpacking python-cffi-backend (1.11.5-1) ...\n",
            "Selecting previously unselected package python-crypto.\n",
            "Preparing to unpack .../05-python-crypto_2.6.1-8ubuntu2_amd64.deb ...\n",
            "Unpacking python-crypto (2.6.1-8ubuntu2) ...\n",
            "Selecting previously unselected package python-enum34.\n",
            "Preparing to unpack .../06-python-enum34_1.1.6-2_all.deb ...\n",
            "Unpacking python-enum34 (1.1.6-2) ...\n",
            "Selecting previously unselected package python-idna.\n",
            "Preparing to unpack .../07-python-idna_2.6-1_all.deb ...\n",
            "Unpacking python-idna (2.6-1) ...\n",
            "Selecting previously unselected package python-ipaddress.\n",
            "Preparing to unpack .../08-python-ipaddress_1.0.17-1_all.deb ...\n",
            "Unpacking python-ipaddress (1.0.17-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../09-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-cryptography.\n",
            "Preparing to unpack .../10-python-cryptography_2.1.4-1ubuntu1.4_amd64.deb ...\n",
            "Unpacking python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Selecting previously unselected package python-dbus.\n",
            "Preparing to unpack .../11-python-dbus_1.2.6-1_amd64.deb ...\n",
            "Unpacking python-dbus (1.2.6-1) ...\n",
            "Selecting previously unselected package python-gi.\n",
            "Preparing to unpack .../12-python-gi_3.26.1-2ubuntu1_amd64.deb ...\n",
            "Unpacking python-gi (3.26.1-2ubuntu1) ...\n",
            "Selecting previously unselected package python-secretstorage.\n",
            "Preparing to unpack .../13-python-secretstorage_2.3.1-2_all.deb ...\n",
            "Unpacking python-secretstorage (2.3.1-2) ...\n",
            "Selecting previously unselected package python-keyring.\n",
            "Preparing to unpack .../14-python-keyring_10.6.0-1_all.deb ...\n",
            "Unpacking python-keyring (10.6.0-1) ...\n",
            "Selecting previously unselected package python-keyrings.alt.\n",
            "Preparing to unpack .../15-python-keyrings.alt_3.0-1_all.deb ...\n",
            "Unpacking python-keyrings.alt (3.0-1) ...\n",
            "Selecting previously unselected package python-pip-whl.\n",
            "Preparing to unpack .../16-python-pip-whl_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\n",
            "Unpacking python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Selecting previously unselected package python-pip.\n",
            "Preparing to unpack .../17-python-pip_9.0.1-2.3~ubuntu1.18.04.4_all.deb ...\n",
            "Unpacking python-pip (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../18-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-setuptools.\n",
            "Preparing to unpack .../19-python-setuptools_39.0.1-2_all.deb ...\n",
            "Unpacking python-setuptools (39.0.1-2) ...\n",
            "Selecting previously unselected package python-wheel.\n",
            "Preparing to unpack .../20-python-wheel_0.30.0-0.2_all.deb ...\n",
            "Unpacking python-wheel (0.30.0-0.2) ...\n",
            "Selecting previously unselected package python-xdg.\n",
            "Preparing to unpack .../21-python-xdg_0.25-4ubuntu1_all.deb ...\n",
            "Unpacking python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-idna (2.6-1) ...\n",
            "Setting up python-pip-whl (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Setting up python-asn1crypto (0.24.0-1) ...\n",
            "Setting up python-crypto (2.6.1-8ubuntu2) ...\n",
            "Setting up python-wheel (0.30.0-0.2) ...\n",
            "Setting up libpython-all-dev:amd64 (2.7.15~rc1-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-cffi-backend (1.11.5-1) ...\n",
            "Setting up python-gi (3.26.1-2ubuntu1) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-enum34 (1.1.6-2) ...\n",
            "Setting up python-dbus (1.2.6-1) ...\n",
            "Setting up python-ipaddress (1.0.17-1) ...\n",
            "Setting up python-pip (9.0.1-2.3~ubuntu1.18.04.4) ...\n",
            "Setting up python-all (2.7.15~rc1-1) ...\n",
            "Setting up python-xdg (0.25-4ubuntu1) ...\n",
            "Setting up python-setuptools (39.0.1-2) ...\n",
            "Setting up python-keyrings.alt (3.0-1) ...\n",
            "Setting up python-all-dev (2.7.15~rc1-1) ...\n",
            "Setting up python-cryptography (2.1.4-1ubuntu1.4) ...\n",
            "Setting up python-secretstorage (2.3.1-2) ...\n",
            "Setting up python-keyring (10.6.0-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Collecting pybind11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/84/fc9dc13ee536ba5e6b8fd10ce368fea5b738fe394c3b296cde7c9b144a92/pybind11-2.6.1-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 3.7MB/s \n",
            "\u001b[?25hCollecting setuptools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/d4/0089d680a610c7b5afda26c1ae588eb363b9050ccf5f33a8c2d1164210f3/setuptools-51.1.2-py3-none-any.whl (784kB)\n",
            "\u001b[K     |████████████████████████████████| 788kB 41.5MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybind11, setuptools\n",
            "  Found existing installation: setuptools 51.1.1\n",
            "    Uninstalling setuptools-51.1.1:\n",
            "      Successfully uninstalled setuptools-51.1.1\n",
            "Successfully installed pybind11-2.6.1 setuptools-51.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK2BZThwFJdw",
        "outputId": "7a2f5d6e-2545-4eb8-a254-977342f7ebdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%writefile requirements.txt\n",
        "gensim\n",
        "pandas\n",
        "razdel\n",
        "hnswlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing requirements.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69T1Gng3842m",
        "outputId": "a0b08972-bc72-4c6b-a3ee-5a6496ff45d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install --upgrade -r requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2MB 1.3MB/s \n",
            "\u001b[?25hRequirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.1.5)\n",
            "Collecting razdel\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Collecting hnswlib\n",
            "  Downloading https://files.pythonhosted.org/packages/97/f0/2fa53f02227df57a566a0f25b910066a50fa0cb12ee120717770d657aabd/hnswlib-0.4.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.6/dist-packages (from gensim->-r requirements.txt (line 1)) (4.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pybind11>=2.0 in /usr/local/lib/python3.6/dist-packages (from hnswlib->-r requirements.txt (line 4)) (2.6.1)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.4.0-cp36-cp36m-linux_x86_64.whl size=1067177 sha256=9a7fa7d97604a29fd5316c769da302cf150ea725ebc3ce49685ec0e3ae9482ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/f2/29/022c2c8b188c4daaf0c46b801d304ffaf0091bbe294b94a2d4\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: gensim, razdel, hnswlib\n",
            "  Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-3.8.3 hnswlib-0.4.0 razdel-0.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk6w5CO_D-by"
      },
      "source": [
        "### Скачиваем датасет на сегодня"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O1IEMGm9l20",
        "outputId": "2a232534-96a0-4aef-e301-e449134fb72f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
        "!gzip -d lenta-ru-news.csv.gz\n",
        "!head -n 2 lenta-ru-news.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-15 17:23:57--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.0/lenta-ru-news.csv.gz\n",
            "Resolving github.com (github.com)... 52.192.72.89\n",
            "Connecting to github.com (github.com)|52.192.72.89|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210115%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210115T172358Z&X-Amz-Expires=300&X-Amz-Signature=579c42fc4b8efc9388017ae0bdec5499a7774bada7957a16c069aba34ab7a5ac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-01-15 17:23:58--  https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/0b363e00-0126-11e9-9e3c-e8c235463bd6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210115%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210115T172358Z&X-Amz-Expires=300&X-Amz-Signature=579c42fc4b8efc9388017ae0bdec5499a7774bada7957a16c069aba34ab7a5ac&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=87156914&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.84.140\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.84.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 527373240 (503M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.gz’\n",
            "\n",
            "lenta-ru-news.csv.g 100%[===================>] 502.94M  16.4MB/s    in 32s     \n",
            "\n",
            "2021-01-15 17:24:31 (15.6 MB/s) - ‘lenta-ru-news.csv.gz’ saved [527373240/527373240]\n",
            "\n",
            "url,title,text,topic,tags\n",
            "https://lenta.ru/news/2018/12/14/cancer/,Названы регионы России с самой высокой смертностью от рака,\"Вице-премьер по социальным вопросам Татьяна Голикова рассказала, в каких регионах России зафиксирована наиболее высокая смертность от рака, сообщает РИА Новости. По словам Голиковой, чаще всего онкологические заболевания становились причиной смерти в Псковской, Тверской, Тульской и Орловской областях, а также в Севастополе. Вице-премьер напомнила, что главные факторы смертности в России — рак и болезни системы кровообращения. В начале года стало известно, что смертность от онкологических заболеваний среди россиян снизилась впервые за три года. По данным Росстата, в 2017 году от рака умерли 289 тысяч человек. Это на 3,5 процента меньше, чем годом ранее.\",Россия,Общество\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLQ6DzCB40Jy"
      },
      "source": [
        "### Обрабатываем датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im2V1KH3EHCL",
        "outputId": "6c6393ba-a21d-482a-d263-efc83e57776c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"lenta-ru-news.csv\", sep=',', quotechar='\\\"', escapechar='\\\\', encoding='utf-8', header=0)\n",
        "dataset.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://lenta.ru/news/2018/12/14/cancer/</td>\n",
              "      <td>Названы регионы России с самой высокой смертно...</td>\n",
              "      <td>Вице-премьер по социальным вопросам Татьяна Го...</td>\n",
              "      <td>Россия</td>\n",
              "      <td>Общество</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/doping/</td>\n",
              "      <td>Австрия не представила доказательств вины росс...</td>\n",
              "      <td>Австрийские правоохранительные органы не предс...</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>Зимние виды</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/disneyland/</td>\n",
              "      <td>Обнаружено самое счастливое место на планете</td>\n",
              "      <td>Сотрудники социальной сети Instagram проанализ...</td>\n",
              "      <td>Путешествия</td>\n",
              "      <td>Мир</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/usa25/</td>\n",
              "      <td>В США раскрыли сумму расходов на расследование...</td>\n",
              "      <td>С начала расследования российского вмешательст...</td>\n",
              "      <td>Мир</td>\n",
              "      <td>Политика</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/integrity/</td>\n",
              "      <td>Хакеры рассказали о планах Великобритании зами...</td>\n",
              "      <td>Хакерская группировка Anonymous опубликовала н...</td>\n",
              "      <td>Мир</td>\n",
              "      <td>Общество</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            url  ...         tags\n",
              "0      https://lenta.ru/news/2018/12/14/cancer/  ...     Общество\n",
              "1      https://lenta.ru/news/2018/12/15/doping/  ...  Зимние виды\n",
              "2  https://lenta.ru/news/2018/12/15/disneyland/  ...          Мир\n",
              "3       https://lenta.ru/news/2018/12/15/usa25/  ...     Политика\n",
              "4   https://lenta.ru/news/2018/12/15/integrity/  ...     Общество\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3aqjNZRF-fj",
        "outputId": "57224b48-5d34-4a33-ebde-f5e177090f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import re\n",
        "import datetime as dt\n",
        "\n",
        "def get_date(url):\n",
        "    dates = re.findall(r\"\\d\\d\\d\\d\\/\\d\\d\\/\\d\\d\", url)\n",
        "    return next(iter(dates), None)\n",
        "  \n",
        "dataset[\"date\"] = dataset[\"url\"].apply(lambda x: dt.datetime.strptime(get_date(x), \"%Y/%m/%d\"))\n",
        "dataset = dataset[dataset[\"date\"] > \"2017-01-01\"]\n",
        "dataset[\"text\"] = dataset[\"text\"].apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
        "dataset[\"title\"] = dataset[\"title\"].apply(lambda x: x.replace(\"\\xa0\", \" \"))\n",
        "dataset.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "      <th>tags</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://lenta.ru/news/2018/12/14/cancer/</td>\n",
              "      <td>Названы регионы России с самой высокой смертно...</td>\n",
              "      <td>Вице-премьер по социальным вопросам Татьяна Го...</td>\n",
              "      <td>Россия</td>\n",
              "      <td>Общество</td>\n",
              "      <td>2018-12-14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/doping/</td>\n",
              "      <td>Австрия не представила доказательств вины росс...</td>\n",
              "      <td>Австрийские правоохранительные органы не предс...</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>Зимние виды</td>\n",
              "      <td>2018-12-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/disneyland/</td>\n",
              "      <td>Обнаружено самое счастливое место на планете</td>\n",
              "      <td>Сотрудники социальной сети Instagram проанализ...</td>\n",
              "      <td>Путешествия</td>\n",
              "      <td>Мир</td>\n",
              "      <td>2018-12-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/usa25/</td>\n",
              "      <td>В США раскрыли сумму расходов на расследование...</td>\n",
              "      <td>С начала расследования российского вмешательст...</td>\n",
              "      <td>Мир</td>\n",
              "      <td>Политика</td>\n",
              "      <td>2018-12-15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/integrity/</td>\n",
              "      <td>Хакеры рассказали о планах Великобритании зами...</td>\n",
              "      <td>Хакерская группировка Anonymous опубликовала н...</td>\n",
              "      <td>Мир</td>\n",
              "      <td>Общество</td>\n",
              "      <td>2018-12-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            url  ...       date\n",
              "0      https://lenta.ru/news/2018/12/14/cancer/  ... 2018-12-14\n",
              "1      https://lenta.ru/news/2018/12/15/doping/  ... 2018-12-15\n",
              "2  https://lenta.ru/news/2018/12/15/disneyland/  ... 2018-12-15\n",
              "3       https://lenta.ru/news/2018/12/15/usa25/  ... 2018-12-15\n",
              "4   https://lenta.ru/news/2018/12/15/integrity/  ... 2018-12-15\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi5NhP-1K7jx",
        "outputId": "07f5c225-196e-4726-d012-b56571c6ec8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_dataset = dataset[dataset[\"date\"] < \"2018-04-01\"]\n",
        "test_dataset = dataset[dataset[\"date\"] > \"2018-04-01\"]\n",
        "print(train_dataset.info())\n",
        "print(test_dataset.info())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 69285 entries, 31339 to 701898\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   url     69285 non-null  object        \n",
            " 1   title   69285 non-null  object        \n",
            " 2   text    69285 non-null  object        \n",
            " 3   topic   69277 non-null  object        \n",
            " 4   tags    65739 non-null  object        \n",
            " 5   date    69285 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), object(5)\n",
            "memory usage: 3.7+ MB\n",
            "None\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 31289 entries, 0 to 31289\n",
            "Data columns (total 6 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   url     31289 non-null  object        \n",
            " 1   title   31289 non-null  object        \n",
            " 2   text    31289 non-null  object        \n",
            " 3   topic   31280 non-null  object        \n",
            " 4   tags    30986 non-null  object        \n",
            " 5   date    31289 non-null  datetime64[ns]\n",
            "dtypes: datetime64[ns](1), object(5)\n",
            "memory usage: 1.7+ MB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD2wHUVt5eAF"
      },
      "source": [
        "# Задачи, которые будем решать\n",
        "* Семантический поиск по заголовку\n",
        "* Рубрикация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grolwlqh4-sr"
      },
      "source": [
        "## Подготовка: разбиение на предложения и токенизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2VWxHQgOTYo",
        "outputId": "5fd4fb6d-d393-4d07-c37c-2580f04b0f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from razdel import tokenize, sentenize\n",
        "from string import punctuation\n",
        "\n",
        "texts = []\n",
        "for text in train_dataset[\"text\"]:\n",
        "    sents = [s.text for s in list(sentenize(text))]\n",
        "    for sent in sents:\n",
        "      sent = [s.text.lower() for s in list(tokenize(sent)) if s.text not in punctuation]\n",
        "      texts.append(sent)\n",
        "    # Разбейте на предложения\n",
        "    # Каждое предложение токенизируйте и список токенов положите в texts.\n",
        "    # Токены приведите к нижнему регистру и избавьтесь от пунктуации.\n",
        "    \n",
        "for title in train_dataset[\"title\"]:\n",
        "    sent = [s.text.lower() for s in list(tokenize(title)) if s.text not in punctuation]\n",
        "    texts.append(sent)\n",
        "    # Считайте заголовок одним предложением\n",
        "\n",
        "assert len(texts) == 827217\n",
        "assert len(texts[0]) > 0\n",
        "assert texts[0][0].islower()\n",
        "print(texts[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['возобновление', 'нормального', 'сотрудничества', 'между', 'россией', 'и', 'нато', 'невозможно', 'пока', 'москва', 'не', 'будет', 'соблюдать', 'нормы', 'международного', 'права']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqxeSd4G6X5G"
      },
      "source": [
        "## Коротко о Word2Vec\n",
        "Обучение:\n",
        "\n",
        "![embeddings training](https://miro.medium.com/max/1400/0*o2FCVrLKtdcxPQqc.png)\n",
        "*From [An implementation guide to Word2Vec using NumPy and Google Sheets\n",
        "](https://towardsdatascience.com/an-implementation-guide-to-word2vec-using-numpy-and-google-sheets-13445eebd281)*\n",
        "\n",
        "![embeddings relations](https://www.tensorflow.org/images/linear-relationships.png)\n",
        "*From [Vector Representations of Words, Tensorflow tutorial](https://www.tensorflow.org/tutorials/representation/word2vec)*\n",
        "\n",
        "Статьи:\n",
        "* Word2Vec: [Distributed Representations of Words and Phrases\n",
        "and their Compositionality](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf), Mikolov et al., 2013\n",
        "* GloVe: [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf), Pennington, Socher, Manning, 2014\n",
        "* fastText: [Enriching Word Vectors with Subword Information](https://arxiv.org/pdf/1607.04606.pdf), Bojanowski, Grave, Joulin, Mikolov, 2016\n",
        "\n",
        "Ссылки:\n",
        "* Word2Vec и fasttext модели для русского: https://rusvectores.org/ru/\n",
        "* fasttext для кучи языков: https://fasttext.cc/\n",
        "* Ещё fasttext модели для русского: http://docs.deeppavlov.ai/en/master/features/pretrained_vectors.html\n",
        "* Отдельная библиотека для русских векторов: https://github.com/natasha/navec\n",
        "* Word2Vec для кучи языков, обученная на Вики: https://wikipedia2vec.github.io/wikipedia2vec/pretrained/\n",
        "* Word2Vec для английского от Гугла: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
        "* Огромная Word2Vec модель для русского: https://zenodo.org/record/400631#.Xa4RPN9fjCI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "maSFl50k6DIv"
      },
      "source": [
        "## Тренируем простую модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i0bx5hBK5yn"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "model = Word2Vec(texts, \n",
        "                 size=32,     # embedding vector size\n",
        "                 min_count=5,  # consider words that occured at least 5 times\n",
        "                 window=5).wv  # define context as a 5-word window around the target word"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gK3c0mM0-RNs"
      },
      "source": [
        "Полноценная тренировка в следующий раз :)\n",
        "А теперь немного потестируем нашу модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdpt9Z7m-faj"
      },
      "source": [
        "## Тестируем модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUwJEbQVJ8B7",
        "outputId": "12cb27e1-b885-483c-e7a7-97283f386bb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.get_vector(\"сша\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.4938401 ,  2.04144   ,  0.94184196, -1.5185319 ,  0.67802364,\n",
              "        2.2063484 , -2.9794836 , -3.022688  , -0.31053418,  2.4689672 ,\n",
              "       -0.6479221 , -2.21922   , -0.6944273 , -5.1766357 , -2.8309417 ,\n",
              "       -0.71933484, -3.6420977 ,  0.4567517 , -0.44306585, -0.6955865 ,\n",
              "       -1.3530957 ,  3.7401102 , -7.396262  ,  0.54243755, -0.20418774,\n",
              "        0.63259655,  2.9469757 ,  1.1263211 , -3.0423503 , -1.247529  ,\n",
              "       -3.585107  , -2.2627656 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZJgVbimJWfn",
        "outputId": "74819b66-cf07-4b59-e388-d35903963c87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.most_similar('сша')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('великобритании', 0.8683749437332153),\n",
              " ('турции', 0.844251275062561),\n",
              " ('кндр', 0.8341597318649292),\n",
              " ('германии', 0.8039666414260864),\n",
              " ('фрг', 0.7998365163803101),\n",
              " ('британии', 0.7878226041793823),\n",
              " ('кнр', 0.7852973937988281),\n",
              " ('японии', 0.7810620069503784),\n",
              " ('соединенных', 0.7711941003799438),\n",
              " ('китая', 0.756449282169342)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "illnNmMTul7E",
        "outputId": "b1dcc1e7-6e14-4d4a-855a-ded4e45dda68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.most_similar([model.get_vector('трамп') - model.get_vector('сша') + model.get_vector('россии')])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('путин', 0.8742369413375854),\n",
              " ('медведев', 0.8365481495857239),\n",
              " ('лукашенко', 0.8058580756187439),\n",
              " ('трамп', 0.7837271690368652),\n",
              " ('жириновский', 0.7791033983230591),\n",
              " ('он', 0.752740740776062),\n",
              " ('мутко', 0.751064658164978),\n",
              " ('порошенко', 0.7492879629135132),\n",
              " ('политик', 0.7434666156768799),\n",
              " ('песков', 0.7349815964698792)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-BAm3tkZcho",
        "outputId": "a5841960-b893-4946-a429-db44ea1d083c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.most_similar([model.get_vector('учитель') - model.get_vector('школа')])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('навальный', 0.7841328382492065),\n",
              " ('учитель', 0.7561232447624207),\n",
              " ('лично', 0.7416640520095825),\n",
              " ('публично', 0.7401352524757385),\n",
              " ('флинн', 0.7398338913917542),\n",
              " ('дутерте', 0.7285616397857666),\n",
              " ('соболезнования', 0.717868447303772),\n",
              " ('кадыров', 0.7043476104736328),\n",
              " ('обама', 0.7003419399261475),\n",
              " ('оппозиционер', 0.6950816512107849)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KovC4m8sZj_E",
        "outputId": "dd8de2e9-d4ad-4c61-fb73-43887339d14f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.most_similar('парк')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('патриот', 0.887389063835144),\n",
              " ('зарядье', 0.8688684701919556),\n",
              " ('бал', 0.8114596605300903),\n",
              " ('южный', 0.8095079660415649),\n",
              " ('остров', 0.7961077690124512),\n",
              " ('синема', 0.7878695726394653),\n",
              " ('горизонт', 0.7837638854980469),\n",
              " ('жк', 0.7732239961624146),\n",
              " ('кавказ', 0.7708346843719482),\n",
              " ('гетман', 0.767069935798645)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apy3l1Xy_fX1"
      },
      "source": [
        "### Задание: Найдите свою аналогию\n",
        "Поиграйтесь с моделью и найдите свои аналогии. Можно здесь, можно на rusvectores\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znoMFNXL-n90"
      },
      "source": [
        "## Визуализируем векторы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ9Xtl58Sbsq"
      },
      "source": [
        "import bokeh.models as bm, bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "\n",
        "def draw_vectors(x, y, radius=10, alpha=0.25, color='blue',\n",
        "                 width=600, height=400, show=True, **kwargs):\n",
        "    output_notebook()\n",
        "    \n",
        "    if isinstance(color, str): \n",
        "        color = [color] * len(x)\n",
        "    data_source = bm.ColumnDataSource({'x' : x, 'y' : y, 'color': color, **kwargs})\n",
        "\n",
        "    fig = pl.figure(active_scroll='wheel_zoom', width=width, height=height)\n",
        "    fig.scatter('x', 'y', size=radius, color='color', alpha=alpha, source=data_source)\n",
        "\n",
        "    fig.add_tools(bm.HoverTool(tooltips=[(key, \"@\" + key) for key in kwargs.keys()]))\n",
        "    if show:\n",
        "        pl.show(fig)\n",
        "    return fig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNgPonL1KXsC"
      },
      "source": [
        "words = sorted(model.vocab.keys(), \n",
        "               key=lambda word: model.vocab[word].count,\n",
        "               reverse=True)[:1000]\n",
        "word_vectors = model.vectors[[model.vocab[word].index for word in words]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wySL7tlja0D8"
      },
      "source": [
        "### PCA\n",
        "\n",
        "Простейший линейный метод сокращения размерностей - __P__rincipial __C__omponent __A__nalysis.\n",
        "\n",
        "PCA ищет оси, при проекции на которые данные будут иметь наибольший разброс.\n",
        "\n",
        "![pca](https://i.stack.imgur.com/Q7HIP.gif)\n",
        "*From [https://stats.stackexchange.com/a/140579](https://stats.stackexchange.com/a/140579)*\n",
        "\n",
        "В результате, можно взять проекции на несколько первых компонент - и сохранить как можно больше информации, сократив размерность.\n",
        "\n",
        "Красивые визуализации можно найти [здесь](http://setosa.io/ev/principal-component-analysis/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlWUB1UsQ-NY"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca_model = PCA(n_components=2)\n",
        "pca_vectors = pca_model.fit_transform(word_vectors)\n",
        "pca_vectors = (pca_vectors - pca_vectors.mean(0)) / pca_vectors.std(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_6xKPpBSfWX"
      },
      "source": [
        "draw_vectors(pca_vectors[:, 0], pca_vectors[:, 1], token=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFUUZyJM_DAa"
      },
      "source": [
        "Получилось не очень понятно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jET8tFuXbEKm"
      },
      "source": [
        "### TSNE\n",
        "\n",
        "Более интересный и сложный (нелинейный) метод для визуализации высокоразмерных пространств - TSNE. Подробно посмотреть на него можно [здесь](https://distill.pub/2016/misread-tsne/) (ещё более красивые картинки!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X_8gVkR_GOa"
      },
      "source": [
        "### Задание: TSNE\n",
        "Сделайте то же самое, но с TSNE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gvbFIlKTeAp"
      },
      "source": [
        "# CODE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuybLGbn_Ra_"
      },
      "source": [
        "draw_vectors(tsne_vectors[:, 0], tsne_vectors[:, 1], token=words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pc0Tcni7_XZ9"
      },
      "source": [
        "## Поиск заголовков"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-W0ag2rT2dE"
      },
      "source": [
        "from razdel import tokenize\n",
        "import numpy as np\n",
        "\n",
        "def get_text_embedding(model, phrase):\n",
        "    embeddings = np.array([model.get_vector(word.text.lower()) if word.text.lower() in model.vocab else np.zeros((model.vector_size,))\n",
        "                           for word in tokenize(phrase)])\n",
        "    return np.mean(embeddings, axis=0)\n",
        "    \n",
        "get_text_embedding(model, \"В Москве нашли\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDMIP-hRDPnc"
      },
      "source": [
        "### Задание: k ближайших заголовков\n",
        "Напишите функцию для поиска похожих на запрос заголовков\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpK83I49VMQ5"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def find_nearest(model, text_vectors, texts, query, k=10):\n",
        "    # YOUR CODE HERE\n",
        "    pass\n",
        "\n",
        "test_titles = test_dataset[\"title\"].tolist()\n",
        "title_vectors = np.array([get_text_embedding(model, title) for title in test_titles])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx4OQahJ935Z"
      },
      "source": [
        "query = \"В Москве нашли\"\n",
        "near_titles = find_nearest(model, title_vectors, test_titles, query)\n",
        "assert len(near_titles) == 10\n",
        "\n",
        "near_titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRuvFP_d1o00"
      },
      "source": [
        "### HNSW-индекс\n",
        "\n",
        "Поиск за log(n)\n",
        "\n",
        "* https://github.com/nmslib/hnswlib\n",
        "* https://habr.com/ru/company/mailru/blog/338360/\n",
        "* https://arxiv.org/ftp/arxiv/papers/1603/1603.09320.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWMxBnwt1oNf"
      },
      "source": [
        "import hnswlib\n",
        "\n",
        "hnsw = hnswlib.Index(space='cosine', dim=title_vectors.shape[1])\n",
        "hnsw.init_index(max_elements=title_vectors.shape[0])\n",
        "hnsw.add_items(title_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sprIy3l77mb3"
      },
      "source": [
        "labels, distances = hnsw.knn_query(get_text_embedding(model, query), k=3)\n",
        "near_titles = [test_titles[i] for i in labels[0]]\n",
        "near_titles"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APIRPR0mDzuZ"
      },
      "source": [
        "## Рубрикация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lYlFzV1EjIF"
      },
      "source": [
        "target_labels = set(train_dataset[\"topic\"].dropna().tolist())\n",
        "target_labels -= {\"69-я параллель\", \"Крым\", \"Культпросвет \", \"Оружие\", \"Бизнес\", \"Путешествия\"}\n",
        "target_labels = list(target_labels)\n",
        "print(target_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d0iwB8MMYgP"
      },
      "source": [
        "pattern = r'(\\b{}\\b)'.format('|'.join(target_labels))\n",
        "\n",
        "train_with_topics = train_dataset[train_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]\n",
        "train_with_topics = train_with_topics.head(20000)\n",
        "\n",
        "test_with_topics = test_dataset[test_dataset[\"topic\"].str.contains(pattern, case=False, na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlFhWgoJZHlI"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "y_train = train_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_train = np.zeros((train_with_topics.shape[0], model.vector_size))\n",
        "for i, embedding in enumerate(train_with_topics[\"text\"]):\n",
        "    X_train[i, :] = get_text_embedding(model, embedding)\n",
        "\n",
        "y_test = test_with_topics[\"topic\"].apply(lambda x: target_labels.index(x)).to_numpy()\n",
        "X_test = np.zeros((test_with_topics.shape[0], model.vector_size))\n",
        "for i, embedding in enumerate(test_with_topics[\"text\"]):\n",
        "    X_test[i, :] = get_text_embedding(model, embedding)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWkHwB8RbwAv"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = SVC()\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usVCxpg1dZDe"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "y_predicted = clf.predict(X_test)\n",
        "print(metrics.classification_report(y_test, y_predicted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wt-3D2s1Fgx1"
      },
      "source": [
        "### Задание: Больше точности\n",
        "\n",
        "Увеличить точность на 0.02+ на той же Word2Vec модели (например, используя tf-idf при построении вектора текста)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6kFWzIlGflX"
      },
      "source": [
        "## Предобученные векторы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdIj4x5TTUSH"
      },
      "source": [
        "### Задание: Модели rusvectores\n",
        "Используя fastText модели с rusvectores, достигните хотя бы такой же точности рубрикации"
      ]
    }
  ]
}